---
title: AMP论文阅读
date: 2025-11-26 18:27:15
tags: 论文
mathjax: true
---


本文是论文 **AMP: Automatically Finding Model Parallel Strategies with Heterogeneity Awareness (NeurIPS 2022)** 的研读笔记~~读后感~~

[论文地址](https://arxiv.org/pdf/2210.07297) | [源码仓库](https://github.com/DachengLi1/AMP)

# TL;DR

启发式算法确定3D并行策略，本文设计的动态规划算法确定流水线并行最优划分，使用提前采样的代价预测训练时间。

# 摘要

（方便书写，默认实际的计算设备是**显卡（GPU）**）

论文在分布式训练，在同构、节点异构和模型异构三种环境下，提出了一个确定以下6个超参数的策略：

1. **数据并行的维度**
2. **张量并行的维度**
3. **流水线并行的维度**
4. **微批次（micro batchsize）大小**
5. **设备布局**（并行策略中哪些显卡视为一组，之间流水线并行，之内张量并行+流水线并行）
6. **流水线层级分配** （流水线并行中，哪几层（layer）组合为一个阶段（stage），及以这个阶段由哪一张显卡负责）

并同时预测实际的训练时间。

# 方法

作为概览的补充，先解释论文试图解决了一个什么样的问题，在此之上提出了一个什么样的模型。

## 提出问题

首先，要训练哪一个模型、训练模型的集群的配置信息和**全局批次大小**（global batchsize）这三个信息是已知的。这里需要指出的是在论文的方法下，全局批次大小还是需要由模型训练者的经验给出。其次是集群虽然一般选择的空间不多，但是需要提前获取：

1. 集群各个节点内显卡间的通信带宽，节点间的通信带宽（或者说网速）。
2. 论文进一步需要各节点的计算能力（这里提前留一个伏笔）。

如果把显卡想象成点，点的权就是显卡的计算能力；显卡间的通信带宽想象成线，线的权就是两张卡的实际通信带宽（当然这里有同节点和不同节点两种情况）。如果不考虑如何确定微批次大小（影响流水线并行中的气泡）、模型划分之后实际上能不能装进显卡的显存里等一些分布式训练独有的问题，那论文试图解决的问题大致上就可以看作是一个拓扑图中如何连接各点，优化关键路径的问题。

更细节的解释和准确的符号定义可以参考论文中3.1节。

## 论文的策略

这里就来到论文的重点部分了。

论文指出了分布式训练的两个特点：

* 一是通过实际跑一轮（epoch）来获取选取的策略的时间开销不够现实，现有的模型运行一轮的时间实在是太长了；
* 二是作为一个离散的规划问题，它的解空间非常大的同时，离散的性质阻碍了使用以梯度为基底的优化方法。

针对上述特点，论文分别提出了对应的解决方法。对于特点一，论文提出了一个能快速估算训练一轮时间的代价模型。而对于特点二，论文提出了一个动态规划算法，用以提前剔除那些没希望的解（也就是搜素算法+剪枝~~但感觉有点强行蹭概念~~）。

下列伪代码是论文设计的策略步骤：
```python
// 集群信息, 神经网络信息, 全局批次大小, budget
Input: C, W, gbs, budget
degrees = enumerate_degrees(C) //穷举所有可能3D并行策略
record = set() // 用于保存结果
for d in degrees do
  /* 遍历给定数据并行维度下的可行微批次大小 */
  for mbs in enumerate_(d.dp) do
    p = placement(C, d) // 启发式设备划分方法
    a = pipe_ast(W, d.pp, p) // 论文提出的最佳流水线划分动态规划算法
    s = (a, mbs, d, p)
    cost = estimate(a, mbs, d, p) // 论文提出的代价模型
    record.add(s, cost)
/* 实际运行前budget个预测结果，以获取实际训练时间 */
best_s = run(record, budget)
return best_s
```

其中的启发式算法是引用了一篇参考文献，这里就~~懒得~~不做展开了。接下来按顺序分别介绍论文设计的代价模型，和动态规划算法实际解决了什么问题。

## 代价模型：自顶向下的分解

论文对于如何建模模型训练花费时间，设计了一个自顶向下的分解策略。

### 顶：数据并行

首先是数据并行的维度，即先考虑把哪些显卡视为一组，组之间流水线并行，组之内张量并行+流水线并行。这是分解中的顶层。此时训练（一轮）的时间可以用下列等式表示：

$$\begin{equation}
\label{eq1}
训练时间=\max(各组训练时间) + \max(各组反向传播时间)
\end{equation}$$

### 中：流水线并行

之后是流水线并行的维度，即考虑怎样把模型中一层一层的神经网络组合成一个阶段，而一个阶段会在最后张量并行的分解后，由一张或多张显卡负责。即对于某一组组内训练（一轮）的时间可表示为：


$$\begin{equation}
\label{eq2}
\begin{aligned}
某组训练时间=&(微批次大小-1) \cdot \max(各阶段训练时间) \\
           & + \sum 各阶段计算时间 \\
           & + \sum 各阶段间通讯时间
\end{aligned}
\end{equation}$$

式$\eqref{eq2}$中，$(微批次大小-1) \cdot max(各阶段训练时间)$是为了刻画“短板效应”（原文straggler effect，直译掉队者效应），即当微批次大小大于1时，总时长会以流水线中花费时长最长的那个时间的相应倍数增加。

### 底：张量并行

最后，在最底层的是张量并行的维度，不过以论文的方法进行到这一步时它的维度其实就是简单的（总显卡数÷数据并行维度÷流水线并行维度）。分解到这里，我们就可以实际考察的是对于某一层，它的计算时间和与下一层的通讯时间如何建模了

### 代价建模：采样

对于计算时间，论文指出如果用（计算量÷显卡浮点计算能力）的方式代替，在计算量较大的时候这种拟合还算贴合实际，但当张量并行的维度逐渐变高之后，导致的误差就会干扰预测的结果。所以论文提出的替代方法是实际对多个张量并行设置进行性能分析，并将结果存储在查找表中。这种方法理论上对于一个特定模型和特定型号显卡，计算时间是相同的，因此论文认为这种方法是可行的。

对于通讯时间，论文则是使用（集合通讯的数据量÷带宽）计算，没有其它的特别处理。（但伏笔+1）

获得了两个时间的具体表达方法之后，就可以倒着从低向上，通过式$\eqref{eq1}$和式$\eqref{eq2}$估算模型训练（一轮的）时间了。

## 流水线并行的层划分：动态规划算法

这部分则是论文（我认为）最主要的创新点。论文提出了一个问题：对于某模型，给定三种并行的策略和微批次大小，如果可以进行划分的话，怎样将所有层划分成多个阶段，并保证某一个组内的训练时间（式$\eqref{eq2}$）最小？（需要特意指出的是，此时这一个组内具体可用显卡和它们的连接方式，即计算能力和通讯带宽是已经确定的）

这部分正是设计的动态规划算法试图解决的部分，同时也让论文的方法区别于了彻底的穷举法。

为了方便打字，这一部分将会使用大量的符号，而不像之前那样用意义代替符号表达式。为方便阅读，这里先给出所有涉及的符号和它的意义：

| 符号 | 意义 |论文符号|
| :----: | :----: | :----: |
| $mbs$ | 微批次大小 | $gas$ |
| $L$ | 神经网络总层数 | $L$ |
| $S$ | （策略划分的）阶段数 | $k$、$pp$ |
| $cost^{layer}_{e,i}$ | 第i层的计算时间 | $t^{layer}_i$ |
| $cost_{e,i}$ | 第i阶段的计算时间 | $t_i$ |
| $cost^{layer}_{e,i}$ | 第i和i+1层之间的通讯时间 | 无 |
| $cost_{c,i}$ | 第i和i+1阶段之间的通讯时间 | $e_i$ |

不过对于$cost^{layer}_{e,j}$和$cost^{layer}_{c,j}$是怎么得来的，这里也有一个小小的伏笔。接下来开始正式介绍该算法。

设一个神经网络模型有$L$层，且策略指定分成指定的$S$个计算阶段，引入一个辅助变量$m$和它的取值空间$M$，则对于子问题$i$层和$j$个阶段的训练时间，可以把式$\eqref{eq2}$写成动态规划数组：

$$\begin{equation}
dp[i][j][m] = (mbs-1)\cdot \max(0,\max_{1\leq j' \leq j}(cost_{e,j'})-m)+\sum_{j'=1}^{j-1}cost_{c,j'}+\sum_{j'=1}^{j}cost_{e,j'}
\end{equation}$$

注意引入变量$m$后与原式的差异，它的作用会在后续解释。但可以看出当$i=L,j=S,m=0$时，该数组会给出上述问题的求解。

进一步给出递推表达式如下：


$$\begin{equation}
\begin{aligned}
dp[i][j][m] =& \min_{ j \leq i' \leq i-1,m \in M}(dp[i'][j-1][max(\sum_{i''=i'+1}^{i}cost^{layer}_{e,i''},m)] \\
    &+(mbs-1)\cdot max(0,\sum_{j'=i'+1}^{i}cost^{layer}_{e,j'} -m) \\
    &+\sum_{i''=i'+1}^{i}cost^{layer}_{e,i''} +cost^{layer}_{c,i'})
\end{aligned}
\end{equation}$$

本文将由浅入深讲解该递推表达式是如何得出的。但解释变量$m$需要一点篇幅，所以先把变量$m$放一边，即动态规划数组退化成$dp[i][j]$的情况。

### 当不存在变量$m$时会有什么问题

只要提前告诉你这个问题能动态规划算法解决，想出来如下一个递推式还是比较容易的。对于$dp[i][j]$，它的值可以如下拆分：

```text
  "前半"   cost^layer_{c,i'}  "后半"
1,2......i'<--------------->i'+1......i
\_________/        ^        \_________/
  i'个层          切断       i'+1到i层
 j-1个阶段                    第j阶段
```

当切断在$i'$时：

* 对于前半部分，自然就是$dp[i'][j-1]$
* 对于后部分，也可以自然想到是$\sum_{i''=i'+1}^{i}t^{layer}_{e,i''}$
* 再者就是需要加上$i'$和$i'+1$之间的通信时间
* 嗯？短板效应怎么表达？前半计算时间最大的阶段似乎没有提供？我怎么才能知道它在前半还就是后半？

短板效应如何计算的问题，个人有个想法是每轮更新的时候实际记录当前计算时间的最高的阶段的值，相当于顺便做一个类似子序列最大值的动态规划（甚至应该可以把后文的时间复杂度压到$O(S\cdot L^2)$）。

但回到论文本身，这就是引入辅助变量$m$试图解决的问题了。

### 如何正确地计算短板效应

首先介绍变量$m$是什么，它的取值空间是什么：它实际的意义是所有可能的阶段、即任意单个或一段连续层的总计算时间，外加上取值`0`（虽然实际上会遇到有的层的计算时间就是0，但点明取值有0是保证算法的正确性）。

设本次和上次的切分的位置分别为$i'$和$i''$，同样的本次和上次的后半层的总计算时间为$t_{i''}$和$t_{i'}$。此时稍将递推式中前半的数组展开一次就会得到一个类似于如下的表达式：

$$\begin{equation}
...+(mbs-1)\cdot(max(0,t_{i''}-max(0,t_{i'}))+max(0,t_{i'}-m))...
\end{equation}$$

再加上一个引理：

$$\begin{equation}
\label{eq:lemma}
\begin{aligned}
&max\{0, t_{i''} - max\{t_{i'}, m\}\} + max\{0, t_{i'} - m\}\\
=&max\{0, max\{t_{i''}, t_{i'}\} - m\}
\end{aligned}
\end{equation}$$

脑补一下$dp[L][S][m]$完全展开的样子，再将式$\eqref{eq:lemma}$带入，会大致得到如下一个东西：

$$\begin{equation}
...+(mbs-1)\cdot max(0,\max_{1\leq j\leq S}(cost^{layer}_{e,j}-m))...
\end{equation}$$

再带入$m=0$，很显然这就是所需计算的短板效应。

对于引理的证明，简单来讲就是一个分类讨论，可以去看原论文的附录~~绝对不是连复制粘贴都懒得干了~~。此时还待解决的问题就只有初始值了，但初始值的计算非常简单，也直接省略了。

### 小细节

首先最明显容易注意的是对于所有可能的计算时间$m$，因为它肯定不是一个像是`0,1,2,3...`的连续序列，设计动态规划数组的时候显然不会真的直接用$m$作为数组的下标。

在实际写代码的时候，会用一个对象`possible`包装变量`m`，即`possible[m]`和`m=possible.index(cur_sum)`的方式来表达`m`。考虑到有已知取值，反过来求下标的需求，这个对象可以是去重的有序数组、查找树甚至哈希表。论文源代码选取的是python中的`set`去重后转化为`list`对象。

另外一个容易注意到的问题是$dp[L][S][0]$似乎只能得到最小的总时间，但在实际训练时自然是需要具体的阶段切分方式的。

联想给出具体的最短路径的Dijkstra算法，可以想到实际编程的时候，动态规划数组不需要一定是一个数字型。

一种方式是可以是一个包含了第$j$阶段具体切在何处的结构体`{i',time}`，再通过`i'`处的最佳`j-1`切分依次回向查找。但这里会遇到一个问题是`i'`处最佳`j-1`切分的`m`值如何确定，这涉及到上次的`m`和本次切分“后半”的计算总时间,递推计算表达式太复杂~~太懒~~就不具体给出了。

另一种是论文源代码实现的方式`{partion,time}`，即直接在上一次的划分信息上加上本次的划分信息`{i',i'+1...}`。这样做的好处是可以做成滚动数组（虽然粗算了一下可能节省不了存储空间，论文源代码也确实没做），当然最重要的是最后提取切分方式也足够简单直观。

### 复杂度分析

**空间复杂度：** 由于求解的过程发生在实际训练前，而对于能训练当代神经网络的设备，内存是完全管够的。加上根据代码实现~~应该~~略有不同，这里就省略了。

**时间复杂度：** 首先对于辅助变量$m$，显然有$\binom{L-1}{2}$可能值，即时间复杂度为$O(L^2)$。
动态规划每一次更新需要考虑$O(L)$个切分位置。再算上动态规划数组$dp[i][j][m]$还有另外两个维度，分别是$O(L)$和$O(S)$。最后可以得到总的时间复杂度$O(S\cdot L^4)$，这显然比起穷举所有$S$个切分位置的$\binom{L-1}{S-1}$好上太多了。

# 实验&效果

这部分不是关注重点，就简单提一下了。对具体数字感数字的话可以点开论文原文看看。

首先论文用的是发表那会流行的Megatron-Deepspeed框架来实现3D并行。当然阅读源码的话，为了支持当时还不支持的自定义流水线阶段划分对框架进行了一些修改，这一部分也一并提供在源代码的仓库中了。

下表是~~纯偷懒~~做的表格，可以对具体效果有一个大致的了解。

| 实验名称  | 集群配置                                                                                 | 模型配置                                                 | 对比对象                                     | 效果                                                                     |
|:-----:|:------------------------------------------------------------------------------------:|:----------------------------------------------------:|:----------------------------------------:|:----------------------------------------------------------------------:|
| 同构环境  | 4×AWS EC2 g4dn.12xlarge节点，每节点4×T4 GPU，节点内50Gbps PCIe，节点间50Gbps                       | GPT-2 (L=24, H=1024)，batch size=32                   | Megatron, AMP, SA(模拟退火)              | Megatron最优1.32s；AMP最优1.20s；SA最优1.57s。AMP能找到与调优的策略相当或略优的结果             |
| 集群异构  | 3×AWS EC2 p3.8xlarge (4×V100, 170Gbps NVLink节点内, 10Gbps节点间) + 1×g4dn.12xlarge (4×T4) | GPT-2 (L=24, H=1024)，batch size=32                   | Megatron-LM, RS(随机搜索), AMP, SA           | Megatron-LM最优1.97s；RS最优1.71s；AMP最优1.28s；SA最优1.46s。AMP相比Megatron提升1.54× |
| 模型异构  | 4×AWS EC2 p3.8xlarge (4×V100)                                                        | 改进版TransGAN：12层dim=1024 + 12层dim=16，batch size=64 | Megatron-LM, AMP w/参数均衡, AMP w/层数均衡, AMP | Megatron-LM最优1.89s；参数均衡2.19s；层数均衡1.25s；AMP最优1.07s。AMP相比Megatron提升1.77× |


# 不足之初&思考

首先介绍~~翻译~~论文原文中已经点明的待改进的问题：

1. 没有考虑显卡能不能装下分割后的模型训练。
    - 不过这对于使用非TensorFlow的神经训练框架是常见的，而且也是一个常见的改进方向。
    - 但是由于分布式方法尚未彻底成熟的现况，也只能是针对个别大模型训练框架，不仅是劳神费力做出来，还需要一个长期痛苦的维护。不如说这件事只能期待提供框架背后的团队。
2. 流水线阶段划分的算法时间复杂度$O(S\cdot L^4)$对于目前模型层数$L$越来越夸张的趋势来说不太妙。
    - 论文提到可以考虑一些例如operator clustering的策略来让分解之后的$L$尽量低。
    - 当然原文中说流水线划分在整个优化过程中占比太大的问题，~~个人觉得有一部分是得怪在python身上~~。

然后是一些个人提出的问题：

3. 把显卡的通信带宽认为是定值是不太现实的。
    - 正如模型有越切越小，实际计算时间会越偏离单纯的计算复杂度÷计算能力，通信的时候也会出现这个问题。

4. 论文的优化策略，主体仍然是引用的启发式算法。
    - 也就是虽然论文提出的流水线划分算法确实精妙，但其解决的问题太过具体，也很难再扩展到同时考虑3D的优化上。

5. （虽然是琢磨源码的时候看出来的）默认使用按顺序生成的显卡编号`Global Rank`，在流水线阶段划分的时候默认使用了这个顺序。
    - 尽管启发式算法会倾向在集群的节点内做张量+流水线并行，但如果涉及到同时节点内间不同带宽的显卡通信的情况，是一定会影响本文的流水线阶段划分算法最优的正确性的。
    - 而且就算是节点内显卡通信带宽不一致的情况也是很有可能的。比如服务器上常见的多CPU配置，两个CPU下属的显卡间通信就会在内存中多中转一次。（~~加钱用NVLink可破~~）

6. （也是看代码的时候看出来的）代价模型中的计算时间本质上还是一轮训练的采样。
    - 正因为还是采样，如果集群的配置出现了再小的会干扰显卡运行~~干活~~的变动，也会导致代价模型的预测可信度变低。一时想不到如何改进的话，也可以尝试说明策略对采样的敏感度如何。

# 扩展阅读
* [DLC：论文的源码分析]()
  - ~~会写的~~，但可以先看看这个[复现的时候顺手重构的](https://github.com/Ariasuko/AMP)
* [如何确定论文中的通信带宽？]()
  - ~~一定会写的~~